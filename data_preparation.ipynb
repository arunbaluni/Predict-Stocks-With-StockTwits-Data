{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preparation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "upX47oYQ-OpZ"
      },
      "source": [
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kectM3tS-O0s"
      },
      "source": [
        "!pip install pyarrow\n",
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjvhl5tA-mJD"
      },
      "source": [
        "# bookcorpus and ag_news dataset from huggingface\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset_bookcorpus = load_dataset(\"bookcorpus\", split='train[:10%]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRMMV_Wz-mci"
      },
      "source": [
        "dataset_ag = load_dataset(\"ag_news\", split='train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-573JhTZ_EwQ"
      },
      "source": [
        "dataset_ag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKdvgJJIzGk6"
      },
      "source": [
        "dataset_ag = dataset_ag.sort(column='label')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSS_PEbGX3sR"
      },
      "source": [
        "dataset_ag['label']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm0ma9IeX3vm"
      },
      "source": [
        "dataset_ag = dataset_ag[60000:90000]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUKter5lIU4H"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZupijDvUH4Hi"
      },
      "source": [
        "# Import Module\n",
        "import os\n",
        "  \n",
        "# Folder Path\n",
        "path = \"/content/drive/MyDrive/Practicum/data\"\n",
        "  \n",
        "# Change the directory\n",
        "os.chdir(path)\n",
        "  \n",
        "# Read text File\n",
        "\n",
        "df_list = []\n",
        "  \n",
        "def read_text_file(file_path):\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = pd.read_json(file_path).T\n",
        "        data_body = data.filter(['body'], axis=1)\n",
        "        df_list.append(data_body)\n",
        "  \n",
        "  \n",
        "# iterate through all file\n",
        "for file in os.listdir():\n",
        "    # Check whether file is in text format or not\n",
        "    if file.endswith(\".json\"):\n",
        "        file_path = f\"{path}/{file}\"\n",
        "  \n",
        "        # call read text file function\n",
        "        read_text_file(file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7NUpBfhIdXq"
      },
      "source": [
        "df_reuters = pd.concat(df_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcwJmo1cY9xl"
      },
      "source": [
        "df_reuters.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TfBjPXoeYux"
      },
      "source": [
        "###Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xPoWMI_aTqt"
      },
      "source": [
        "def removeLinks(text):\n",
        "    text = re.sub(r'http\\S+', '', text, flags=re.MULTILINE)\n",
        "    return text\n",
        "headlines =  list(map(removeLinks, dataset_ag['text']))\n",
        "documents = list(map(removeLinks, dataset_bookcorpus['text']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMkFKyUmaTuK"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tvh9Z3QitaK"
      },
      "source": [
        "def removeHTMLTags(text):\n",
        "    text = re.sub(r'<.*?>', '', text, flags=re.MULTILINE)\n",
        "    return text\n",
        "headlines = list(map(removeHTMLTags, headlines))\n",
        "documents = list(map(removeHTMLTags, documents))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b35fNzM1i2K5"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKhrd2EUi7mV"
      },
      "source": [
        "def removeWordsWithNumbers(text):\n",
        "    return re.sub(r\"\\S*\\d\\S*\", \"\", text).strip()\n",
        "headlines = list(map(removeWordsWithNumbers, headlines))\n",
        "documents = list(map(removeWordsWithNumbers, documents))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF-8-kPoi7qB"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvTyL-7Kem72"
      },
      "source": [
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase\n",
        "headlines = list(map(decontracted, headlines))\n",
        "documents = list(map(decontracted, documents))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUeBq_oAerTt"
      },
      "source": [
        "\n",
        "def removePuctuations(text):\n",
        "    return re.sub(r'[^A-Za-z0-9]+', ' ', text)\n",
        "headlines = list(map(removePuctuations, headlines))\n",
        "documents = list(map(removePuctuations, documents))\n",
        "\n",
        "def removeWhiteSpaces(text):\n",
        "    return text.strip()\n",
        "headlines = list(map(removeWhiteSpaces, headlines))\n",
        "documents = list(map(removeWhiteSpaces, documents))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om2b3KOKeuqd"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zrJXdkueygu"
      },
      "source": [
        "def convertToLowerCase(text):\n",
        "    return text.lower()\n",
        "headlines = list(map(convertToLowerCase, headlines))\n",
        "documents = list(map(convertToLowerCase, documents))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqpIG87vmYte"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/Practicum/Albert/\n",
        "\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCl7uZBJe7fZ"
      },
      "source": [
        "\n",
        "f = open(\"/content/drive/My Drive/Practicum/Albert/combined_book10percent.txt\", \"x\")\n",
        "f = open(\"/content/drive/My Drive/Practicum/Albert/combined_book10percent.txt\", \"w\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrhbddvugCCp"
      },
      "source": [
        "for vocab in documents:\n",
        "  f.write(vocab)\n",
        "  f.write('\\n')\n",
        "  f.write('\\n')\n",
        "\n",
        "for v in headlines:\n",
        "  f.write(v)\n",
        "  f.write('\\n')\n",
        "  f.write('\\n')\n",
        "\n",
        "for vo in list(df_reuters):\n",
        "  f.write(vo)\n",
        "  f.write('\\n')\n",
        "  f.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0onflb83aLLW"
      },
      "source": [
        "print(type(f))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}